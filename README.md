
Hybrid Learning Against Label Noise

Combining Structural Consistency and Contrastive Initialization

This repository contains the code, configurations, and experimental outputs for a course project studying robust learning under label noise in image classification. The project evaluates several practical robustness strategies under a fixed and controlled training pipeline, focusing on real human annotation noise rather than synthetic corruption.

The experiments are conducted on CIFAR-10 (clean labels) and CIFAR-10N (human noisy labels, AGGRE) using a shared ResNet-18 backbone and identical optimization settings to isolate the effect of the robustness mechanisms themselves.

â¸»

ğŸ“Œ Project Overview

Deep neural networks trained with standard cross-entropy tend to memorize noisy labels during late training, which degrades generalization. This issue is especially important when labels come from humans, where disagreement often reflects genuine ambiguity rather than random corruption.

In this project, we perform a controlled comparison of four training variants:
	â€¢	Baseline: Standard cross-entropy training
	â€¢	Structural: Neighbor-consistency regularization in representation space
	â€¢	Hybrid: Structural consistency + agreement-based reweighting
	â€¢	Contrastive-init: Contrastive-style initialization followed by supervised training

All methods:
	â€¢	Use ResNet-18
	â€¢	Train for 100 epochs
	â€¢	Use SGD
	â€¢	Share the same augmentation, optimizer, and evaluation protocol
	â€¢	Optionally run under a 30% subset mode for reproducibility under limited compute

â¸»

ğŸ§  Methods Implemented

Baseline

Standard cross-entropy loss treating observed labels as ground truth.

Structural

Adds a neighbor-consistency regularization term that encourages predictions of nearby samples in feature space to be similar. This reduces memorization of locally mislabeled examples.

Hybrid

Combines:
	â€¢	Agreement-based down-weighting of suspicious samples
	â€¢	The same neighbor-consistency regularization used in Structural

Contrastive-init

Uses contrastive-style initialization of the encoder, followed by standard supervised training. No contrastive objective is applied during noisy supervised training.

â¸»

ğŸ“‚ Repository Structure

Hybrid-CV-Project/
â”‚
â”œâ”€â”€ train.py                # Main training entry point
â”œâ”€â”€ eval.py                 # Evaluation utilities
â”œâ”€â”€ model.py                # ResNet-18 and model components
â”œâ”€â”€ hybrid_loss.py          # Hybrid loss and agreement weighting
â”œâ”€â”€ pretrain.py             # Contrastive-style initialization
â”œâ”€â”€ utils.py                # Shared helpers
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ neighbor_consistency.py
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ plot_learning_curves.py
â”‚   â”œâ”€â”€ plot_embeddings.py
â”‚   â””â”€â”€ make_report_artifacts.py
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ structural/
â”‚   â”œâ”€â”€ hybrid/
â”‚   â”œâ”€â”€ figures (.png)
â”‚   â””â”€â”€ tables (.csv, .md)
â”‚
â”œâ”€â”€ data/                   # (ignored) datasets
â”œâ”€â”€ datasets/               # (ignored) raw data
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

Note: Datasets, checkpoints, and large binaries are intentionally excluded from version control.

â¸»

â–¶ï¸ How to Run

1. Environment Setup

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt


â¸»

2. Training (Example)

Run a quick test using a small subset:

python3 train.py \
  --epochs 1 \
  --dataset cifar10n \
  --subset aggre \
  --subset_fraction 0.01 \
  --model structural

Run a full experiment (example):

python3 train.py \
  --epochs 100 \
  --dataset cifar10n \
  --subset aggre \
  --model hybrid


â¸»

3. Outputs

Training produces:
	â€¢	Learning curves (accuracy & cross-entropy)
	â€¢	Confusion matrices
	â€¢	UMAP / t-SNE embeddings
	â€¢	CSV tables for aggregate and per-class accuracy

All outputs are saved under:

outputs/<method>/<subset>/<timestamp>/


â¸»

ğŸ“Š Evaluation & Visualization
	â€¢	Learning curves track both peak and late-epoch behavior
	â€¢	Confusion matrices highlight class-level ambiguity
	â€¢	UMAP / t-SNE visualize representation geometry under noisy supervision

These diagnostics are used to interpret why certain robustness strategies perform better, not just how well they perform.

â¸»

ğŸ” Reproducibility

To ensure fair comparison:
	â€¢	All methods share the same architecture, optimizer, and schedule
	â€¢	Subset mode enables deterministic training under limited compute
	â€¢	CIFAR-10N evaluation follows the standard protocol using clean test labels

â¸»

ğŸ“ Dataset References
	â€¢	CIFAR-10: Standard image classification benchmark
	â€¢	CIFAR-10N: Human-annotated noisy labels
	â€¢	AGGRE label set used in experiments
	â€¢	Provided by the UCSC-REAL CIFAR-N repository

â¸»

âš ï¸ Notes & Limitations
	â€¢	Results are primarily reported for a single random seed
	â€¢	Subset sampling is not class-stratified
	â€¢	Contrastive-init is evaluated as initialization, not end-to-end contrastive training under noise
	â€¢	A full noise-rate sweep is proposed as future work

â¸»

ğŸ”— Important Links

Project repository:
https://github.com/AmerSaad001/Hybrid-Label-Noise-CV

â¸»

ğŸ“„ License & Usage

This repository accompanies a course project submission and is intended for academic and educational use.

